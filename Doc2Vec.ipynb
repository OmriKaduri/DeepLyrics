{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import create_songs_for, preprocess_texts, parse_raw_songs\n",
    "from Midi_preprocessing import preprocess_midi, encode_midi\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pretty_midi\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "root_path = './'\n",
    "\n",
    "\n",
    "def parse_raw_song(line):\n",
    "    data = []\n",
    "    artist_name_index = line.find(',')\n",
    "    name = line[:artist_name_index].lower().replace(\"\\\"\", \"\").strip()\n",
    "    # The replace between \" to empty added beacuse some names contained it, probably error at the data creation\n",
    "    line_after_name = line[artist_name_index + 1:]\n",
    "    song_name_index = line_after_name.find(',')\n",
    "    song_name = line_after_name[:song_name_index].lower().strip()\n",
    "    lyrics = line_after_name[song_name_index + 1:]\n",
    "    more_than_one = lyrics.find('&  &  &')  # Indicator for 2 songs in same line, bad dataset :(\n",
    "    if more_than_one != -1:\n",
    "        curr_lyrics = lyrics[:more_than_one]\n",
    "    else:\n",
    "        curr_lyrics = lyrics\n",
    "    curr_song = {'name': name, 'song_name': song_name, 'lyrics': curr_lyrics}\n",
    "    if more_than_one != -1:\n",
    "        data.append(curr_song)\n",
    "        more_songs = parse_raw_song(lyrics[more_than_one + len('&  &  &'):])\n",
    "        for song in more_songs:\n",
    "            data.append(song)\n",
    "        return data\n",
    "    else:\n",
    "        return [curr_song]\n",
    "\n",
    "\n",
    "def parse_raw_songs(raw_songs):\n",
    "    songs = []\n",
    "\n",
    "    for raw_song in raw_songs:\n",
    "        curr_songs = parse_raw_song(raw_song)  # Iterate beacuse might contain multiple songs in a raw song line\n",
    "        for song in curr_songs:\n",
    "            songs.append(song)\n",
    "\n",
    "    return songs\n",
    "\n",
    "\n",
    "def create_songs_for(train=True):\n",
    "    if train:\n",
    "        midi_dir = \"midi_files\"\n",
    "        lyrics_file = \"lyrics_train_set.csv\"\n",
    "    else:\n",
    "        midi_dir = \"midi_files/test\"\n",
    "        lyrics_file = \"lyrics_test_set.csv\"\n",
    "\n",
    "    with open(root_path + \"/\" + lyrics_file, 'r') as raw_lyrics:\n",
    "        raw_songs = raw_lyrics.read().splitlines()\n",
    "\n",
    "    songs = parse_raw_songs(raw_songs)\n",
    "\n",
    "    midi_files = all_midi_files(midi_dir)\n",
    "\n",
    "    for i, song in enumerate(songs):\n",
    "        midi_name = song_midi_filename(song)\n",
    "\n",
    "        matched_midi_files = [midi_file for midi_file in midi_files\n",
    "                              if midi_name in midi_file.lower()]\n",
    "\n",
    "        if len(matched_midi_files) != 1:\n",
    "            print(\"OH OH\", len(matched_midi_files), song)\n",
    "            continue\n",
    "\n",
    "        songs[i]['midi_file'] = matched_midi_files[0]\n",
    "\n",
    "        if songs[i]['lyrics'].find('&,,,,') == -1:\n",
    "            songs[i]['lyrics'] = songs[i]['lyrics'] + ' EOS'\n",
    "        else:\n",
    "            songs[i]['lyrics'] = songs[i]['lyrics'].replace('&,,,,', ' EOS')\n",
    "\n",
    "        songs[i]['lyrics'] = ' '.join(nltk.word_tokenize(songs[i]['lyrics']))\n",
    "        songs[i]['lyrics'] = songs[i]['lyrics'].replace('&', 'EOL')\n",
    "\n",
    "        songs[i]['lyrics'] = remove_brackets(songs[i]['lyrics'])\n",
    "\n",
    "        splitted_lyrics = [token for token in nltk.word_tokenize(songs[i]['lyrics']) if token not in string.punctuation]\n",
    "        for j in range(len(splitted_lyrics) - 1):\n",
    "            if songs[i].__contains__('ngrams'):\n",
    "                songs[i]['ngrams'].append(splitted_lyrics[j])\n",
    "            else:\n",
    "                songs[i]['ngrams'] = [splitted_lyrics[j]]\n",
    "            if songs[i].__contains__('labels'):\n",
    "                songs[i]['labels'].append(splitted_lyrics[j + 1])\n",
    "            else:\n",
    "                songs[i]['labels'] = [splitted_lyrics[j + 1]]\n",
    "\n",
    "        \n",
    "#         pad songs[i]['lyrics'] to 400\n",
    "#         ngrams from songs[i]['lyrics'] size2\n",
    "#         for ngram: ngram = ngram[:-1], label = ngram[-1]\n",
    "        songs[i]['ngrams'] = np.array(songs[i]['ngrams'])\n",
    "        songs[i]['labels'] = np.array(songs[i]['labels'])\n",
    "\n",
    "    return songs\n",
    "\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "  \n",
    "def remove_brackets(lyrics):\n",
    "    while lyrics.find('(') != -1:\n",
    "        open_bracket = lyrics.find('(')\n",
    "        close_bracket = lyrics.find(')')\n",
    "        lyrics = lyrics[:open_bracket] + lyrics[close_bracket + 1:]\n",
    "    return lyrics\n",
    "\n",
    "\n",
    "def song_midi_filename(song):\n",
    "    return song['name'].replace(' ', '_') + \"_-_\" + song['song_name'].replace(' ', '_')\n",
    "\n",
    "\n",
    "def all_midi_files(midi_dir):\n",
    "    midi_path = os.path.join(root_path, midi_dir)\n",
    "\n",
    "    return [os.path.join(midi_path, path) for path in os.listdir(midi_path)\n",
    "            if '.mid' in path or '.midi' in path]\n",
    "\n",
    "\n",
    "def create_data_for(train=True):\n",
    "    songs = create_songs_for(train)\n",
    "    \n",
    "    X = np.array([song['ngrams'] for song in songs])\n",
    "    y = np.array([song['labels'] for song in songs])\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def init_tokenizer(text):\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    return tokenizer\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dir = \"midi_files\"\n",
    "lyrics_file = \"lyrics_train_set.csv\"\n",
    "with open(lyrics_file, 'r') as raw_lyrics:\n",
    "    raw_songs = raw_lyrics.read().splitlines()\n",
    "\n",
    "    songs = parse_raw_songs(raw_songs)\n",
    "\n",
    "    midi_files = all_midi_files(midi_dir)\n",
    "\n",
    "    sequences = list()\n",
    "    seq_counts = []\n",
    "    for i, song in enumerate(songs):\n",
    "        seq_count = 0\n",
    "        midi_name = song_midi_filename(song)\n",
    "\n",
    "        matched_midi_files = [midi_file for midi_file in midi_files\n",
    "                              if midi_name in midi_file.lower()]\n",
    "\n",
    "        if len(matched_midi_files) != 1:\n",
    "            print(\"OH OH\", len(matched_midi_files), song)\n",
    "            continue\n",
    "\n",
    "        songs[i]['midi_file'] = matched_midi_files[0]\n",
    "\n",
    "        if songs[i]['lyrics'].find('&,,,,') == -1:\n",
    "            songs[i]['lyrics'] = songs[i]['lyrics'] + ' EOS'\n",
    "        else:\n",
    "            songs[i]['lyrics'] = songs[i]['lyrics'].replace('&,,,,', ' EOS')\n",
    "\n",
    "        songs[i]['lyrics'] = ' '.join(nltk.word_tokenize(songs[i]['lyrics']))\n",
    "        songs[i]['lyrics'] = songs[i]['lyrics'].replace('&', 'EOL')\n",
    "\n",
    "        songs[i]['lyrics'] = remove_brackets(songs[i]['lyrics'])\n",
    "\n",
    "        splitted_lyrics = [token for token in nltk.word_tokenize(songs[i]['lyrics']) if token not in string.punctuation]\n",
    "        \n",
    "  \n",
    "        n = 4\n",
    "        splitted_lyrics = (['<s>'] * (n-1)) + splitted_lyrics\n",
    "    \n",
    "        for j in range(0, len(splitted_lyrics) - n):\n",
    "            sequence = splitted_lyrics[j:j+n]\n",
    "            sequences.append(sequence)\n",
    "            seq_count += 1\n",
    "        \n",
    "        seq_counts.append(seq_count)\n",
    "            \n",
    "            \n",
    "all_songs_words = ' '.join(np.hstack(sequences).flatten()) + ' eos'\n",
    "tokenizer = init_tokenizer(all_songs_words)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "sequences = [np.array(tokenizer.texts_to_sequences(seq)).flatten() for seq in sequences]\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=n)\n",
    "\n",
    "# split into input and output elements\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=len(word_index))\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt', encoding=\"utf8\")\n",
    "EMBEDDING_DIM = 300\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "unk_words = []\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        unk_words.append(word)\n",
    "\n",
    "print(\"Found\", len(unk_words) + 1, \"Unknown words\")\n",
    "print(unk_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "files = create_songs_for(train=True)\n",
    "\n",
    "onlyfiles = [file['midi_file'] for file in files]\n",
    "\n",
    "encoded_midis = encode_midi(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument, FAST_VERSION\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(encoded_midis)]\n",
    "\n",
    "assert FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "doc2vec_model = Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "                        epochs=20, workers=cores, alpha=0.05)\n",
    "\n",
    "\n",
    "\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "print(\"%s vocabulary scanned & state initialized\" % doc2vec_model)\n",
    "\n",
    "%time doc2vec_model.train(tagged_data, total_examples=len(tagged_data), epochs=doc2vec_model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_train = []\n",
    "for song_index, doc in tqdm(enumerate(encoded_midis)):\n",
    "    embedding = doc2vec_model.infer_vector(doc)\n",
    "    midi_train.extend([embedding] * seq_counts[song_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.pow(2.0, cross_entropy)\n",
    "\n",
    "    return perplexity\n",
    "\n",
    "# def categorical_crossentropy(y_true, y_pred):\n",
    "#   return tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Input, Concatenate, Dropout, Masking, BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "# import keras.backend as K\n",
    "# K.clear_session()\n",
    "\n",
    "text_in = Input(shape=(n-1,))\n",
    "# masking = Masking()(text_in)\n",
    "embedding = Embedding(input_dim=len(word_index) + 1, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], mask_zero=True, trainable=False)(text_in)\n",
    "text_norm = BatchNormalization()(embedding)\n",
    "text_drop = Dropout(0.3)(text_norm)\n",
    "lstm1 = LSTM(units=128)(text_drop)\n",
    "lstm_norm = LayerNormalization()(lstm1)\n",
    "# lstm2 = LSTM(units=128, return_sequences=True)(lstm1)\n",
    "# lstm3 = LSTM(units=128)(lstm2)\n",
    "midi_in = Input(shape=(100,))\n",
    "midi_norm = BatchNormalization()(midi_in)\n",
    "concat = Concatenate()([lstm_norm, midi_norm])\n",
    "dropout = Dropout(0.1)(concat)\n",
    "dense = Dense(units=len(word_index), activation='softmax')(dropout)\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='./logs/{}'.format(time()), batch_size=128, write_graph=True)\n",
    "\n",
    "nn = Model(inputs=[text_in, midi_in], outputs=[dense])\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam()\n",
    "\n",
    "nn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[perplexity])\n",
    "\n",
    "history = nn.fit([X,np.array(midi_train)], y, batch_size=128,\n",
    "          epochs=10, validation_split=0.2, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from the model\n",
    "def generate_seq(model, song_embedding, tokenizer, max_length, seed_text, n_words):\n",
    "    result = [seed_text]\n",
    "    \n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([result])\n",
    "        encoded = pad_sequences(encoded, maxlen=max_length, padding='pre')\n",
    "        # predict a word in the vocabulary\n",
    "        probs = model.predict([encoded, song_embedding])\n",
    "        predicted_id = np.where(probs[0] == np.random.choice(probs[0], p=probs[0]))[0][0]\n",
    "        # map predicted word index to word\n",
    "        out_word = tokenizer.index_word[predicted_id]\n",
    "        # append to input\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = create_songs_for(train=False)\n",
    "\n",
    "test_onlyfiles = [file['midi_file'] for file in test_files]\n",
    "print(test_onlyfiles)\n",
    "encoded_testmidis = encode_midi(test_onlyfiles)\n",
    "print(encoded_testmidis)\n",
    "test_vectors = []\n",
    "\n",
    "for midi in encoded_testmidis:\n",
    "    test_vectors.append(doc2vec_model.infer_vector(midi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, song in enumerate(test_vectors):\n",
    "    for word in ['hello', 'beautiful', 'world']:\n",
    "        print(test_onlyfiles[index], word, ':')\n",
    "        print(generate_seq(nn, song.reshape((1,100)), tokenizer, n-1, word, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
