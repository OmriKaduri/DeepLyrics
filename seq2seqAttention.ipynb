{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import create_songs_for, preprocess_texts\n",
    "from Midi_preprocessing import preprocess_midi, encode_midi\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = create_songs_for()\n",
    "\n",
    "text_tokenizer, text_sequences, embedding_matrix = preprocess_texts([song['lyrics'] for song in songs], 200)\n",
    "midi_tokenizer, midi_sequences = preprocess_midi([song['midi_file'] for song in songs], 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(midi_sequences, text_sequences, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "vocab_inp_size = len(midi_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(text_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(len(input_tensor_val))\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2SeqAttention import Encoder, BahdanauAttention, Decoder\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "attention_layer = BahdanauAttention(50)\n",
    "\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, embedding_matrix, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "    \n",
    "        dec_hidden = enc_hidden\n",
    "    \n",
    "        dec_input = tf.expand_dims([text_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "    \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    dec_input = tf.expand_dims([text_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "    \n",
    "      # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "        # passing enc_output to the decoder\n",
    "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "    \n",
    "        loss += loss_function(targ[:, t], predictions)\n",
    "    \n",
    "        # using teacher forcing\n",
    "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    train_total_loss = 0\n",
    "    val_total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        train_total_loss += batch_loss\n",
    "\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(valid_dataset.take(steps_per_epoch_val)):\n",
    "        batch_loss = valid_step(inp, targ, enc_hidden)\n",
    "        val_total_loss += batch_loss \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        train_total_loss / steps_per_epoch))\n",
    "    print('Validation Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        val_total_loss / steps_per_epoch_val))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def evaluate(sentence, initial_word):\n",
    "    inputs = tf.convert_to_tensor([sentence])\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([text_tokenizer.word_index[initial_word]], 0)\n",
    "\n",
    "    for t in range(200):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        random_index = random.randint(0,1)\n",
    "        softmax_values = scipy.special.softmax(predictions[0])\n",
    "        predicted_id = np.where(predictions[0].numpy() == np.random.choice(predictions[0], p=softmax_values))[0][0]\n",
    "\n",
    "        result += text_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if text_tokenizer.index_word[predicted_id] == 'eos':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence\n",
    "\n",
    "\n",
    "def translate(sentence, initial_word):\n",
    "    result, sentence = evaluate(sentence, initial_word)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "test_files = create_songs_for(train=False)\n",
    "\n",
    "test_onlyfiles = [file['midi_file'] for file in test_files]\n",
    "print(test_onlyfiles)\n",
    "encoded_testmidis = encode_midi(test_onlyfiles)\n",
    "\n",
    "test_sequenecs = pad_sequences(midi_tokenizer.texts_to_sequences(encoded_testmidis), maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, song in enumerate(test_sequenecs):\n",
    "    for word in ['hello', 'beautiful', 'world']:\n",
    "        print(test_onlyfiles[index], word, ':')\n",
    "        print(translate(song, word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
